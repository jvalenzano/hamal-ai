# Hamal: AI-Powered Validation Framework for TechTrend
## North Star Document v1.0

**Date:** January 10, 2026  
**Author:** AI Lead, TechTrend Inc.  
**Status:** Draft for Development  

---

## Vision Statement

**Hamal is an agentic research swarm that transforms rough agency requests into validated, buildable project specifications—autonomously.**

When an agency sends us an email saying "we need AI for post-fire recovery," Hamal:
1. **Interrogates the problem** (5 Whys, root cause analysis, stakeholder mapping)
2. **Researches precedents** (similar gov projects, technical approaches, failed attempts)
3. **Assesses feasibility** (technical complexity, compliance burden, timeline, cost)
4. **Generates architecture** (stack recommendations, fixed-price estimates, risk mitigation)
5. **Produces decision report** (Go/No-Go with evidence, ready for $5K Design proposal)

**All of this happens through an agent swarm—not templates. Not wizards. Autonomous research with human oversight.**

---

## The Problem We're Solving

### Current State (Manual Process)
When TechTrend receives a new opportunity (RANGER, TrailWatch, FAA modernization):

1. **Problem Discovery:** 1-2 weeks of back-and-forth emails/calls to understand what they actually need
2. **Research:** Manual searches for similar projects, competitors, technical precedents
3. **Feasibility:** Gut-check on "can we build this in 6-16 weeks?"
4. **Architecture:** Draft tech stack, estimate costs, identify risks
5. **Proposal:** Package into $5K Design phase deliverable

**Bottlenecks:**
- "Truly understanding the problem is the long pole" (stated pain point)
- Tribal knowledge in AI Lead's head (not documented, not scalable)
- No pattern recognition across similar projects (reinventing architecture each time)
- New team members can't run Design phase independently

**Time cost:** 10-20 hours per opportunity (Design phase labor)

### Desired State (Hamal-Assisted Process)
Input: Agency charter, email, meeting notes (unstructured)  
Process: Agent swarm researches, validates, architects (1-2 hours human oversight)  
Output: Complete Design phase report (research.md, validation.md, architecture.md, decision.md)

**Time savings goal:** 10-20 hours → 2-4 hours (5-10x faster)

---

## Core Principles

### 1. **Agents Do the Research, Not Templates**
Hamal is NOT a questionnaire. It's an autonomous research team.

- Agents search the web for similar government projects (DigitalGov, Challenge.gov, SAM.gov)
- Agents analyze past TechTrend projects for reusable patterns (RANGER architecture → new project)
- Agents identify risks by finding failed projects with similar characteristics
- Agents iterate on the problem statement themselves (Socratic self-questioning, not interviewing the user)

**Human role:** Provide initial context, review agent outputs, make final decision.

### 2. **Domain Skills Are Baked In**
Agents understand TechTrend's specific context:

- **Forest Service domain:** Wildfire management, trail maintenance, ranger operations, multi-agency coordination
- **Federal procurement:** FedRAMP compliance, 508 accessibility, PII/CUI handling, contract vehicles
- **TechTrend stack:** FastAPI, React, GCP (Vertex AI, AlloyDB, Cloud Run), fixed-price scoping methodology
- **Historical projects:** RANGER (multi-agent coordination), TrailWatch (citizen reporting), past wins/losses

**This is not generic startup validation.** This is government AI project scoping for a Google Cloud Partner consultancy.

### 3. **A2UI (Agentic UI) Provides Real-Time Insights**
The interface is NOT static forms. It's a living dashboard that updates as agents work:

- **Progress visualization:** "Research Agent found 6 similar projects... Feasibility Agent scoring technical complexity... Architecture Agent generating stack recommendation..."
- **Dynamic charts:** Risk heatmaps, cost breakdowns, timeline Gantt charts
- **Iterative refinement:** User can redirect agents mid-research ("focus more on compliance risks")
- **Exportable artifacts:** Markdown reports, PDFs, slide decks (for client proposals)

**Why this matters:** 
1. Learning goal (AI Lead wants to master A2UI patterns for future projects)
2. Team collaboration (Builders can see what agents discovered, not just final output)
3. Client demos (show agencies "here's how we validated your project")

### 4. **One Input → Complete Validation Output**
Hamal produces the same artifacts that manual process creates—but autonomously:

| Manual Output | Hamal Output | Time Savings |
|---------------|--------------|--------------|
| `research.md` (competitor analysis, similar projects) | ✅ Auto-generated by Research Agent | 3-5 hours |
| `validation.md` (risks, Mom Test questions, red flags) | ✅ Auto-generated by Validation Agent | 2-4 hours |
| `architecture.md` (stack, costs, timeline) | ✅ Auto-generated by Architecture Agent | 4-6 hours |
| `decision.md` (Go/No-Go with evidence) | ✅ Auto-generated by Decision Agent | 1-2 hours |

**Total time savings per project:** 10-17 hours → Can evaluate 3x more opportunities per month.

---

## Success Metrics

### Primary Metric: **Time Savings**
- **Goal:** Design phase drops from 10-20 hours → 2-4 hours (5-10x improvement)
- **Measurement:** Track hours spent per $5K Design engagement (before/after Hamal)

### Secondary Metrics:
1. **Quality:** % of fixed-price projects that stay within budget (risk assessment accuracy)
2. **Velocity:** Opportunities evaluated per month (pipeline throughput)
3. **Scaling:** Time for new Builder to run Design phase independently (onboarding speed)
4. **Reusability:** % of projects where Hamal identifies reusable architecture from past work

### MVP Success Criteria (8 weeks):
- [ ] Hamal runs on 3 real TechTrend opportunities (RANGER, TrailWatch, 1 new project)
- [ ] Saves 5+ hours per project (validated via time tracking)
- [ ] Produces research.md that surfaces 3+ insights AI Lead wouldn't have found manually
- [ ] A2UI demonstrates 3+ dynamic visualizations (progress, risks, costs)
- [ ] New Builder can use Hamal outputs to draft architecture without AI Lead handholding

---

## Non-Goals (What Hamal Is NOT)

### ❌ **Not a Consumer SaaS for Founders**
- No B2C validation tool (like ValidatorAI)
- No $29/mo subscription model
- No mass-market product-market fit chase

### ❌ **Not a Generic Idea Validator**
- Not for startups, not for hardware, not for consumer apps
- Specifically tuned for **government AI projects** at **TechTrend**

### ❌ **Not a Template/Wizard System**
- Not "answer 20 questions → get report"
- Agents do autonomous research, not interview the user

### ❌ **Not Production GCP Infrastructure (Yet)**
- MVP is local/lightweight (Vercel + Supabase or Render)
- GCP migration (Vertex AI, AlloyDB) is Phase 2 (after validation)

---

## Constraints & Context

### Team
- **AI Lead** (full-stack, orchestrator, context engineer)
- **Small Builder team** (1-3 developers, growing)
- **Antigravity partnership** (GCP-native collaboration, shared language for meetings)

### Tools in Use
- **Cursor** (AI-assisted coding)
- **Claude Code** (agentic development)
- **Antigravity** (GCP orchestration, team collaboration)
- **Multiple LLM workflows** (need unified approach)

### Domain
- **TechTrend AI Factory:** 4-phase model (Design → Build → Deploy → Transfer)
- **Government clients:** USDA Forest Service, federal agencies
- **Fixed-price delivery:** 6-16 week projects, $40-100K range
- **Compliance requirements:** FedRAMP, 508, PII/CUI, procurement vehicles

---

## The Ask

**Build Hamal as a personal AI Chief of Staff for TechTrend's AI Lead.**

Not for external customers (yet). Not for monetization (yet). Just:
1. Solve the Design phase bottleneck
2. Learn agentic orchestration + A2UI patterns
3. Create scalable knowledge base for growing team

If it works internally, optionality exists for:
- TechTrend team-wide adoption
- Client-facing demo tool (show agencies our validation rigor)
- B2B SaaS for other gov contractors (future monetization)

But first: **Prove it works for one person (AI Lead) on real projects.**

---

## Next Steps

1. **Review this North Star** (does it capture the vision?)
2. **Read System Architecture doc** (how agents + A2UI work together)
3. **Review 8-Week Build Plan** (phased delivery, decision gates)
4. **Decide:** Build with Antigravity? Solo in Cursor? Hybrid approach?

---

**Version:** 1.0  
**Status:** Draft—ready for development scoping  
**Contact:** AI Lead, TechTrend Inc.
